{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from  sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(df,trainlabel,cate_cols,test_,feature,num_class):\n",
    "    '''\n",
    "    @param df: 训练数据 DataFrame\n",
    "    @param trainlabel：训练标签 string  eg. 'label'\n",
    "    @param cate_cols: 类别变量名 list  eg. ['col1','col2'...]\n",
    "    @param test_ : 测试数据 DataFrame\n",
    "    @param feature ：所有训练特征 list  eg. ['feat1','feat2'...]\n",
    "\n",
    "    @return sub_preds: 预测数据\n",
    "    \n",
    "    '''\n",
    "    train_= df.copy()\n",
    "    auc = []\n",
    "    n_splits = 5\n",
    "    oof_lgb = np.zeros([len(train_),num_class])\n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=2019)\n",
    "    stratifiedKfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2019)\n",
    "    sub_preds = np.zeros([test_.shape[0],num_class])\n",
    "    sub_preds1 = np.zeros([test_.shape[0],n_splits])\n",
    "    use_cart = True\n",
    "    cate_cols = cate_cols\n",
    "    label = trainlabel\n",
    "    pred = list(feature)\n",
    "    params = {\n",
    "        'learning_rate': 0.02,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective':'multiclass',\n",
    "        #'metric':'multi-error',\n",
    "        'num_class':num_class,\n",
    "        'num_leaves':60,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'seed': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction_seed': 5,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'max_depth':-1,\n",
    "        'nthread': 8,\n",
    "        'verbose': 1,\n",
    " #       'is_unbalanace':True,\n",
    "#         'lambda_l1': 0.4,  \n",
    "#         'lambda_l2': 0.5, \n",
    "        'device': 'cpu'\n",
    "    }\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_[pred],train_[[label]]), start=1):\n",
    "        print('the %s training start ...'%n_fold)\n",
    "\n",
    "        train_x, train_y,train_weight = train_[pred].iloc[train_idx], train_[[label]].iloc[train_idx],train_[['weight']].iloc[train_idx]\n",
    "        valid_x, valid_y,valid_weight = train_[pred].iloc[valid_idx], train_[[label]].iloc[valid_idx],train_[['weight']].iloc[valid_idx]\n",
    "        #x = train_['bid'].iloc[valid_idx]\n",
    "        print(train_y.shape)\n",
    "        if use_cart:\n",
    "            dtrain = lgb.Dataset(train_x, label=train_y, categorical_feature=cate_cols,weight=train_weight.values.flatten(order='F'))\n",
    "            dvalid = lgb.Dataset(valid_x, label=valid_y, categorical_feature=cate_cols)\n",
    "            #dvalid1 = lgb.Dataset(test_[pred], label=test_[['label']], categorical_feature=cate_cols)\n",
    "\n",
    "        else:\n",
    "            dtrain = lgb.Dataset(train_x, label= train_y)\n",
    "            dvalid = lgb.Dataset(valid_x, label= valid_y)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[dvalid],\n",
    "            early_stopping_rounds = 100,\n",
    "            verbose_eval=100\n",
    "           ,feval=eval_error\n",
    "        )\n",
    "        \n",
    "        sub_preds += clf.predict(test_[pred].values,num_iteration=1000)/ folds.n_splits\n",
    "        sub_preds1[:,n_fold-1] = clf.predict(test_[pred].values,num_iteration=400).argmax(axis=1)\n",
    "        train_pred = clf.predict(valid_x,num_iteration=clf.best_iteration)\n",
    "        y_pred = train_pred.argmax(axis=1)\n",
    "        oof_lgb[valid_idx] = train_pred\n",
    "    #print('MEAN AUC:',np.mean(auc))\n",
    "    \n",
    "    return sub_preds,oof_lgb,clf,sub_preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_avli_Q3 = pd.read_csv(r'D:\\学习\\厦门银行/train/avli/cust_avli_Q3.csv')\n",
    "cust_avli_Q4 = pd.read_csv(r'D:\\学习\\厦门银行/train/avli/cust_avli_Q4.csv')\n",
    "cust_avli_test = pd.read_csv(r'D:\\学习\\厦门银行/test/avli/cust_avli_Q1.csv')\n",
    "label_Q3 = pd.read_csv(r'D:\\学习\\厦门银行/train/y/y_Q3_3.csv')\n",
    "label_Q4 = pd.read_csv(r'D:\\学习\\厦门银行/train/y/y_Q4_3.csv')\n",
    "label_Q3['label'] = label_Q3.label + 1\n",
    "label_Q4['label'] = label_Q4.label + 1\n",
    "cust_avli_Q3 = cust_avli_Q3.merge(label_Q3,on='cust_no',how='left')\n",
    "cust_avli_Q4 = cust_avli_Q4.merge(label_Q4,on='cust_no',how='left')\n",
    "\n",
    "cust_avli_Q3['pre_label'] = np.nan\n",
    "last_label = label_Q3[['cust_no','label']]\n",
    "last_label.columns = ['cust_no','pre_label']\n",
    "cust_avli_Q4 = cust_avli_Q4.merge(last_label,on='cust_no',how='left')\n",
    "\n",
    "last_label = label_Q4[['cust_no','label']]\n",
    "last_label.columns = ['cust_no','pre_label']\n",
    "cust_avli_test = cust_avli_test.merge(last_label,on='cust_no',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data= pd.read_csv(r'D:\\学习\\厦门银行/1210/train.csv')\n",
    "feature = Train_data.drop(['cust_no','label','weight'],axis=1).columns\n",
    "cust_avli_test= pd.read_csv(r'D:\\学习\\厦门银行/1210/cust_avli_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1 training start ...\n",
      "(116236, 1)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.682143\tvalid_0's kappa_score: 0.457145\n",
      "[200]\tvalid_0's multi_logloss: 0.647355\tvalid_0's kappa_score: 0.467509\n",
      "[300]\tvalid_0's multi_logloss: 0.638277\tvalid_0's kappa_score: 0.472822\n",
      "[400]\tvalid_0's multi_logloss: 0.634641\tvalid_0's kappa_score: 0.475312\n",
      "[500]\tvalid_0's multi_logloss: 0.63223\tvalid_0's kappa_score: 0.47774\n",
      "[600]\tvalid_0's multi_logloss: 0.630628\tvalid_0's kappa_score: 0.479582\n",
      "[700]\tvalid_0's multi_logloss: 0.629324\tvalid_0's kappa_score: 0.480184\n",
      "Early stopping, best iteration is:\n",
      "[645]\tvalid_0's multi_logloss: 0.630061\tvalid_0's kappa_score: 0.480615\n",
      "the 2 training start ...\n",
      "(116237, 1)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.686107\tvalid_0's kappa_score: 0.450416\n",
      "[200]\tvalid_0's multi_logloss: 0.652205\tvalid_0's kappa_score: 0.46286\n",
      "[300]\tvalid_0's multi_logloss: 0.643542\tvalid_0's kappa_score: 0.469331\n",
      "[400]\tvalid_0's multi_logloss: 0.639743\tvalid_0's kappa_score: 0.473336\n",
      "[500]\tvalid_0's multi_logloss: 0.63795\tvalid_0's kappa_score: 0.472951\n",
      "Early stopping, best iteration is:\n",
      "[454]\tvalid_0's multi_logloss: 0.638688\tvalid_0's kappa_score: 0.474074\n",
      "the 3 training start ...\n",
      "(116237, 1)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.683817\tvalid_0's kappa_score: 0.458741\n",
      "[200]\tvalid_0's multi_logloss: 0.648897\tvalid_0's kappa_score: 0.472375\n",
      "[300]\tvalid_0's multi_logloss: 0.639149\tvalid_0's kappa_score: 0.477073\n",
      "[400]\tvalid_0's multi_logloss: 0.635652\tvalid_0's kappa_score: 0.478075\n",
      "[500]\tvalid_0's multi_logloss: 0.633697\tvalid_0's kappa_score: 0.479908\n",
      "[600]\tvalid_0's multi_logloss: 0.631868\tvalid_0's kappa_score: 0.481447\n",
      "[700]\tvalid_0's multi_logloss: 0.630832\tvalid_0's kappa_score: 0.481252\n",
      "Early stopping, best iteration is:\n",
      "[606]\tvalid_0's multi_logloss: 0.63175\tvalid_0's kappa_score: 0.482166\n",
      "the 4 training start ...\n",
      "(116237, 1)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.684709\tvalid_0's kappa_score: 0.450942\n",
      "[200]\tvalid_0's multi_logloss: 0.650708\tvalid_0's kappa_score: 0.463101\n",
      "[300]\tvalid_0's multi_logloss: 0.641631\tvalid_0's kappa_score: 0.467673\n",
      "[400]\tvalid_0's multi_logloss: 0.638091\tvalid_0's kappa_score: 0.47022\n",
      "[500]\tvalid_0's multi_logloss: 0.635993\tvalid_0's kappa_score: 0.472203\n",
      "[600]\tvalid_0's multi_logloss: 0.634529\tvalid_0's kappa_score: 0.472801\n",
      "[700]\tvalid_0's multi_logloss: 0.633286\tvalid_0's kappa_score: 0.473144\n",
      "[800]\tvalid_0's multi_logloss: 0.632181\tvalid_0's kappa_score: 0.475626\n",
      "[900]\tvalid_0's multi_logloss: 0.631481\tvalid_0's kappa_score: 0.476443\n",
      "[1000]\tvalid_0's multi_logloss: 0.630701\tvalid_0's kappa_score: 0.477059\n",
      "[1100]\tvalid_0's multi_logloss: 0.630149\tvalid_0's kappa_score: 0.478047\n",
      "[1200]\tvalid_0's multi_logloss: 0.62956\tvalid_0's kappa_score: 0.477823\n",
      "Early stopping, best iteration is:\n",
      "[1108]\tvalid_0's multi_logloss: 0.630068\tvalid_0's kappa_score: 0.478593\n",
      "the 5 training start ...\n",
      "(116237, 1)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.681994\tvalid_0's kappa_score: 0.459492\n",
      "[200]\tvalid_0's multi_logloss: 0.647525\tvalid_0's kappa_score: 0.471905\n",
      "[300]\tvalid_0's multi_logloss: 0.638241\tvalid_0's kappa_score: 0.476578\n",
      "[400]\tvalid_0's multi_logloss: 0.63459\tvalid_0's kappa_score: 0.480542\n",
      "[500]\tvalid_0's multi_logloss: 0.632419\tvalid_0's kappa_score: 0.481379\n"
     ]
    }
   ],
   "source": [
    "def eval_error(pred,train_set):\n",
    "    \n",
    "    labels = train_set.get_label()\n",
    "    pred = pred.reshape((3,int(len(pred)/3))).T\n",
    "    y_pred = pred.argmax(axis=1)\n",
    "    score = cohen_kappa_score(labels,y_pred)\n",
    "    return 'kappa_score',score,True\n",
    "\n",
    "sub_preds,oof_lgb,clf,sub_preds1 = model_train(Train_data,trainlabel='label',cate_cols=[],test_=cust_avli_test,feature=feature,num_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_avli_test['label'] = sub_preds.argmax(axis=1) - 1\n",
    "cust_avli_test[['cust_no','label']].to_csv(r'D:\\学习\\厦门银行/1210/baseline3.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
